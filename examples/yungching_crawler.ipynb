{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crawl yungching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "os.makedirs('yungching_crawl_data', exist_ok=True)\n",
    "\n",
    "\n",
    "#url = 'https://buy.yungching.com.tw/region/%E5%8F%B0%E5%8C%97%E5%B8%82-_c/'\n",
    "\n",
    "header_s={\n",
    "    'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Encoding':'gzip, deflate, sdch, br',\n",
    "    'Accept-Language':'en-US,en;q=0.8',\n",
    "    'Cache-Control':'no-cache',\n",
    "    'Connection':'keep-alive',\n",
    "    'Cookie':'_last_search_data=%7B%22searchFor%22%3A%22all%22%2C%22mainType%22%3A%22region%22%2C%22addr%22%3A%5B%5B%22%E5%8F%B0%E5%8C%97%E5%B8%82%22%5D%2C%5B%22%22%5D%5D%2C%22mrt%22%3A%5B%5D%2C%22isMap%22%3Afalse%2C%22price%22%3A%5B%22%22%2C%22%22%5D%2C%22pyeong%22%3A%5B%22%22%2C%22%22%5D%2C%22keywords%22%3A%5B%22%22%5D%2C%22filterBy%22%3A%5B%22%22%5D%2C%22sortBy%22%3A%5B%22undefined%22%5D%2C%22advConditions%22%3A%7B%22car%22%3A%5B%5D%2C%22houseType%22%3A%5B%5D%2C%22accessible%22%3A%5B%5D%2C%22houseAge%22%3A%5B%5D%2C%22directions%22%3A%5B%5D%2C%22floors%22%3A%7B%22sp%22%3A%5B%22false%22%5D%2C%22val%22%3A%5B%5D%7D%2C%22rooms%22%3A%7B%22sp%22%3A%5B%22false%22%5D%2C%22val%22%3A%5B%5D%7D%2C%22sp%22%3A%5B%5D%7D%2C%22od%22%3A%22%22%2C%22pyeongType%22%3A0%2C%22coords%22%3A%22%22%2C%22searchBland%22%3A%22%E5%85%A8%E9%83%A8%E4%BB%B2%E4%BB%8B%22%2C%22originalDomain%22%3A%22%22%7D; userid=4ab02f33-f90f-4578-bde1-e0799e65d646; TRID_G=e0bcf196-3909-493e-acd2-795fb5d4b925; ez2o_UNID=1522215564489490; __ltmwga=utmcsr=(direct)|utmcmd=(none); WMX_Channel=,1,; _last_search_data=%7B%22searchFor%22%3A%22all%22%2C%22mainType%22%3A%22region%22%2C%22addr%22%3A%5B%5B%22%E5%8F%B0%E5%8C%97%E5%B8%82%22%5D%2C%5B%22%22%5D%5D%2C%22mrt%22%3A%5B%5D%2C%22isMap%22%3Afalse%2C%22price%22%3A%5B%22%22%2C%22%22%5D%2C%22pyeong%22%3A%5B%22%22%2C%22%22%5D%2C%22keywords%22%3A%5B%22%22%5D%2C%22filterBy%22%3A%5B%22%22%5D%2C%22sortBy%22%3A%5B%22undefined%22%5D%2C%22advConditions%22%3A%7B%22car%22%3A%5B%5D%2C%22houseType%22%3A%5B%5D%2C%22accessible%22%3A%5B%5D%2C%22houseAge%22%3A%5B%5D%2C%22directions%22%3A%5B%5D%2C%22floors%22%3A%7B%22sp%22%3A%5B%22false%22%5D%2C%22val%22%3A%5B%5D%7D%2C%22rooms%22%3A%7B%22sp%22%3A%5B%22false%22%5D%2C%22val%22%3A%5B%5D%7D%2C%22sp%22%3A%5B%5D%7D%2C%22od%22%3A%22%22%2C%22pyeongType%22%3A0%2C%22coords%22%3A%22%22%2C%22searchBland%22%3A%22%E5%85%A8%E9%83%A8%E4%BB%B2%E4%BB%8B%22%2C%22originalDomain%22%3A%22%22%7D; userid=4ab02f33-f90f-4578-bde1-e0799e65d646; _gat_UA-35108030-1=1; _dc_gtm_UA-35108030-1=1; yawbewkcehc=0; __asc=582560d51626b1e3bd135ad7d44; __auc=5983cf801626561cf77f6c77d0b; __ltm_https_flag=true; _pk_id.5.f7c6=0225278645f347ab.1522119332.2.1522216079.1522215567.; _pk_ses.5.f7c6=*; _uetsid=_uetafb7b681; _ga=GA1.4.1967887631.1522119332; _gid=GA1.4.1424818617.1522215566',\n",
    "    'Host':'buy.yungching.com.tw',\n",
    "    'Pragma':'no-cache',\n",
    "    'Referer':'https://buy.yungching.com.tw/region/%E5%8F%B0%E5%8C%97%E5%B8%82-_c/',\n",
    "    'Upgrade-Insecure-Requests':'1',\n",
    "    'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'\n",
    "}\n",
    "\n",
    "###\n",
    "def get_items_from_page(url, header_s, pg_num):\n",
    "    real_url = url+'?pg='+str(pg_num)\n",
    "    yungching_items = {}\n",
    "    items_info = []\n",
    "    try:\n",
    "        res = requests.get(real_url, headers=header_s)\n",
    "        res.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(res.text, \"html5lib\")\n",
    "        items_list = soup.select('.l-item-list .m-list-item')\n",
    "        total_items_num = len(items_list)\n",
    "        print(\"total items num = %s\"%total_items_num)\n",
    "        for num in range(total_items_num):\n",
    "            one_item_info = {}\n",
    "            one_item_info['item-description'] = re.sub(' +', ' ', items_list[num].select('.item-info .item-description')[0].text.replace('\\xa0', '').replace('\\n', ' ').replace('\\u3000', ''))\n",
    "            one_item_info['item-info-detail'] = re.sub(' +', ' ', items_list[num].select('.item-info .item-info-detail')[0].text.replace('\\n', ' ').strip())\n",
    "            item_tags_num = len(items_list[num].select('.item-info .item-tags span'))\n",
    "            print('tags num = %s'%item_tags_num)\n",
    "            one_item_info['item-tags'] = []\n",
    "            for tag_num in range(item_tags_num):\n",
    "                one_item_info['item-tags'].append(items_list[num].select('.item-info .item-tags span')[tag_num].text)\n",
    "            one_item_info['item-price'] = items_list[num].select('.item-price .price .price-num')[0].text\n",
    "            one_item_info['title'] = items_list[num].select('.item-info a')[0]['title'].split(' ',1)[0]\n",
    "            one_item_info['address'] = items_list[num].select('.item-info a')[0]['title'].split(' ',1)[1]\n",
    "            one_item_info['detail-href'] = items_list[num].select('.item-info a')[0]['href']\n",
    "            items_info.append(one_item_info)\n",
    "            print('%s append succeed'%str(num))\n",
    "        yungching_items['items_info'] = items_info\n",
    "        with open('yungching_crawl_data/yungching_items_pg'+str(pg_num)+'.json', 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(yungching_items, outfile, ensure_ascii=False)\n",
    "        print('[INFO]Done crawl page %s'%pg_num)\n",
    "        #return yungching_items\n",
    "    except:\n",
    "        print(\"wrong url\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_total_pg_num(url, header_s):\n",
    "        res = requests.get(url, headers=header_s)\n",
    "        res.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(res.text, \"html5lib\")\n",
    "        total_pg_num = int(re.findall( 'pg=(\\d{,5})', soup.select('.m-pagination-bd li a[ga_label=\"buy_page_last\"]')[0]['href'])[0])\n",
    "        return total_pg_num\n",
    "\n",
    "def yungching_crawler(url, header_s):\n",
    "    total_pg_num = get_total_pg_num(url, header_s)\n",
    "    print('total pages num = %s'%total_pg_num)\n",
    "    for pg_num in range(1, total_pg_num+1):\n",
    "        get_items_from_page(url, header_s, pg_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pages num = 313\n",
      "total items num = 20\n",
      "tags num = 5\n",
      "0 append succeed\n",
      "tags num = 2\n",
      "1 append succeed\n",
      "tags num = 5\n",
      "2 append succeed\n",
      "tags num = 3\n",
      "3 append succeed\n",
      "tags num = 4\n",
      "4 append succeed\n",
      "tags num = 2\n",
      "5 append succeed\n",
      "tags num = 4\n",
      "6 append succeed\n",
      "tags num = 5\n",
      "7 append succeed\n",
      "tags num = 3\n",
      "8 append succeed\n",
      "tags num = 2\n",
      "9 append succeed\n",
      "tags num = 4\n",
      "10 append succeed\n",
      "tags num = 4\n",
      "11 append succeed\n",
      "tags num = 2\n",
      "12 append succeed\n",
      "tags num = 4\n",
      "13 append succeed\n",
      "tags num = 2\n",
      "14 append succeed\n",
      "tags num = 2\n",
      "15 append succeed\n",
      "tags num = 2\n",
      "16 append succeed\n",
      "tags num = 2\n",
      "17 append succeed\n",
      "tags num = 2\n",
      "18 append succeed\n",
      "tags num = 1\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 1\n",
      "total items num = 20\n",
      "tags num = 3\n",
      "0 append succeed\n",
      "tags num = 2\n",
      "1 append succeed\n",
      "tags num = 4\n",
      "2 append succeed\n",
      "tags num = 3\n",
      "3 append succeed\n",
      "tags num = 0\n",
      "4 append succeed\n",
      "tags num = 2\n",
      "5 append succeed\n",
      "tags num = 4\n",
      "6 append succeed\n",
      "tags num = 3\n",
      "7 append succeed\n",
      "tags num = 2\n",
      "8 append succeed\n",
      "tags num = 3\n",
      "9 append succeed\n",
      "tags num = 3\n",
      "10 append succeed\n",
      "tags num = 3\n",
      "11 append succeed\n",
      "tags num = 2\n",
      "12 append succeed\n",
      "tags num = 4\n",
      "13 append succeed\n",
      "tags num = 2\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 4\n",
      "16 append succeed\n",
      "tags num = 4\n",
      "17 append succeed\n",
      "tags num = 4\n",
      "18 append succeed\n",
      "tags num = 4\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 2\n",
      "total items num = 20\n",
      "tags num = 2\n",
      "0 append succeed\n",
      "tags num = 3\n",
      "1 append succeed\n",
      "tags num = 3\n",
      "2 append succeed\n",
      "tags num = 2\n",
      "3 append succeed\n",
      "tags num = 4\n",
      "4 append succeed\n",
      "tags num = 4\n",
      "5 append succeed\n",
      "tags num = 3\n",
      "6 append succeed\n",
      "tags num = 3\n",
      "7 append succeed\n",
      "tags num = 3\n",
      "8 append succeed\n",
      "tags num = 2\n",
      "9 append succeed\n",
      "tags num = 3\n",
      "10 append succeed\n",
      "tags num = 3\n",
      "11 append succeed\n",
      "tags num = 3\n",
      "12 append succeed\n",
      "tags num = 4\n",
      "13 append succeed\n",
      "tags num = 3\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 4\n",
      "16 append succeed\n",
      "tags num = 4\n",
      "17 append succeed\n",
      "tags num = 3\n",
      "18 append succeed\n",
      "tags num = 5\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 3\n",
      "total items num = 20\n",
      "tags num = 3\n",
      "0 append succeed\n",
      "tags num = 3\n",
      "1 append succeed\n",
      "tags num = 4\n",
      "2 append succeed\n",
      "tags num = 4\n",
      "3 append succeed\n",
      "tags num = 5\n",
      "4 append succeed\n",
      "tags num = 2\n",
      "5 append succeed\n",
      "tags num = 2\n",
      "6 append succeed\n",
      "tags num = 3\n",
      "7 append succeed\n",
      "tags num = 3\n",
      "8 append succeed\n",
      "tags num = 3\n",
      "9 append succeed\n",
      "tags num = 4\n",
      "10 append succeed\n",
      "tags num = 3\n",
      "11 append succeed\n",
      "tags num = 1\n",
      "12 append succeed\n",
      "tags num = 5\n",
      "13 append succeed\n",
      "tags num = 3\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 4\n",
      "16 append succeed\n",
      "tags num = 2\n",
      "17 append succeed\n",
      "tags num = 2\n",
      "18 append succeed\n",
      "tags num = 4\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 4\n",
      "total items num = 20\n",
      "tags num = 3\n",
      "0 append succeed\n",
      "tags num = 1\n",
      "1 append succeed\n",
      "tags num = 4\n",
      "2 append succeed\n",
      "tags num = 2\n",
      "3 append succeed\n",
      "tags num = 2\n",
      "4 append succeed\n",
      "tags num = 1\n",
      "5 append succeed\n",
      "tags num = 2\n",
      "6 append succeed\n",
      "tags num = 4\n",
      "7 append succeed\n",
      "tags num = 4\n",
      "8 append succeed\n",
      "tags num = 2\n",
      "9 append succeed\n",
      "tags num = 4\n",
      "10 append succeed\n",
      "tags num = 3\n",
      "11 append succeed\n",
      "tags num = 5\n",
      "12 append succeed\n",
      "tags num = 3\n",
      "13 append succeed\n",
      "tags num = 5\n",
      "14 append succeed\n",
      "tags num = 6\n",
      "15 append succeed\n",
      "tags num = 3\n",
      "16 append succeed\n",
      "tags num = 2\n",
      "17 append succeed\n",
      "tags num = 3\n",
      "18 append succeed\n",
      "tags num = 4\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 5\n",
      "total items num = 20\n",
      "tags num = 4\n",
      "0 append succeed\n",
      "tags num = 2\n",
      "1 append succeed\n",
      "tags num = 3\n",
      "2 append succeed\n",
      "tags num = 4\n",
      "3 append succeed\n",
      "tags num = 2\n",
      "4 append succeed\n",
      "tags num = 4\n",
      "5 append succeed\n",
      "tags num = 4\n",
      "6 append succeed\n",
      "tags num = 2\n",
      "7 append succeed\n",
      "tags num = 4\n",
      "8 append succeed\n",
      "tags num = 4\n",
      "9 append succeed\n",
      "tags num = 3\n",
      "10 append succeed\n",
      "tags num = 2\n",
      "11 append succeed\n",
      "tags num = 4\n",
      "12 append succeed\n",
      "tags num = 3\n",
      "13 append succeed\n",
      "tags num = 5\n",
      "14 append succeed\n",
      "tags num = 4\n",
      "15 append succeed\n",
      "tags num = 3\n",
      "16 append succeed\n",
      "tags num = 4\n",
      "17 append succeed\n",
      "tags num = 3\n",
      "18 append succeed\n",
      "tags num = 5\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 6\n",
      "total items num = 20\n",
      "tags num = 3\n",
      "0 append succeed\n",
      "tags num = 1\n",
      "1 append succeed\n",
      "tags num = 3\n",
      "2 append succeed\n",
      "tags num = 4\n",
      "3 append succeed\n",
      "tags num = 4\n",
      "4 append succeed\n",
      "tags num = 4\n",
      "5 append succeed\n",
      "tags num = 1\n",
      "6 append succeed\n",
      "tags num = 4\n",
      "7 append succeed\n",
      "tags num = 4\n",
      "8 append succeed\n",
      "tags num = 3\n",
      "9 append succeed\n",
      "tags num = 3\n",
      "10 append succeed\n",
      "tags num = 3\n",
      "11 append succeed\n",
      "tags num = 1\n",
      "12 append succeed\n",
      "tags num = 3\n",
      "13 append succeed\n",
      "tags num = 4\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 3\n",
      "16 append succeed\n",
      "tags num = 2\n",
      "17 append succeed\n",
      "tags num = 5\n",
      "18 append succeed\n",
      "tags num = 3\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 7\n",
      "total items num = 20\n",
      "tags num = 2\n",
      "0 append succeed\n",
      "tags num = 3\n",
      "1 append succeed\n",
      "tags num = 3\n",
      "2 append succeed\n",
      "tags num = 4\n",
      "3 append succeed\n",
      "tags num = 1\n",
      "4 append succeed\n",
      "tags num = 4\n",
      "5 append succeed\n",
      "tags num = 5\n",
      "6 append succeed\n",
      "tags num = 3\n",
      "7 append succeed\n",
      "tags num = 3\n",
      "8 append succeed\n",
      "tags num = 3\n",
      "9 append succeed\n",
      "tags num = 2\n",
      "10 append succeed\n",
      "tags num = 4\n",
      "11 append succeed\n",
      "tags num = 3\n",
      "12 append succeed\n",
      "tags num = 3\n",
      "13 append succeed\n",
      "tags num = 4\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 3\n",
      "16 append succeed\n",
      "tags num = 3\n",
      "17 append succeed\n",
      "tags num = 4\n",
      "18 append succeed\n",
      "tags num = 4\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 8\n",
      "total items num = 20\n",
      "tags num = 5\n",
      "0 append succeed\n",
      "tags num = 2\n",
      "1 append succeed\n",
      "tags num = 4\n",
      "2 append succeed\n",
      "tags num = 3\n",
      "3 append succeed\n",
      "tags num = 4\n",
      "4 append succeed\n",
      "tags num = 4\n",
      "5 append succeed\n",
      "tags num = 2\n",
      "6 append succeed\n",
      "tags num = 4\n",
      "7 append succeed\n",
      "tags num = 4\n",
      "8 append succeed\n",
      "tags num = 4\n",
      "9 append succeed\n",
      "tags num = 4\n",
      "10 append succeed\n",
      "tags num = 2\n",
      "11 append succeed\n",
      "tags num = 3\n",
      "12 append succeed\n",
      "tags num = 4\n",
      "13 append succeed\n",
      "tags num = 2\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 6\n",
      "16 append succeed\n",
      "tags num = 1\n",
      "17 append succeed\n",
      "tags num = 3\n",
      "18 append succeed\n",
      "tags num = 3\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 9\n",
      "total items num = 20\n",
      "tags num = 3\n",
      "0 append succeed\n",
      "tags num = 2\n",
      "1 append succeed\n",
      "tags num = 4\n",
      "2 append succeed\n",
      "tags num = 3\n",
      "3 append succeed\n",
      "tags num = 2\n",
      "4 append succeed\n",
      "tags num = 4\n",
      "5 append succeed\n",
      "tags num = 4\n",
      "6 append succeed\n",
      "tags num = 1\n",
      "7 append succeed\n",
      "tags num = 1\n",
      "8 append succeed\n",
      "tags num = 4\n",
      "9 append succeed\n",
      "tags num = 3\n",
      "10 append succeed\n",
      "tags num = 2\n",
      "11 append succeed\n",
      "tags num = 5\n",
      "12 append succeed\n",
      "tags num = 3\n",
      "13 append succeed\n",
      "tags num = 1\n",
      "14 append succeed\n",
      "tags num = 3\n",
      "15 append succeed\n",
      "tags num = 3\n",
      "16 append succeed\n",
      "tags num = 5\n",
      "17 append succeed\n",
      "tags num = 4\n",
      "18 append succeed\n",
      "tags num = 3\n",
      "19 append succeed\n",
      "[INFO]Done crawl page 10\n"
     ]
    }
   ],
   "source": [
    "url = 'https://buy.yungching.com.tw/region/%E5%8F%B0%E5%8C%97%E5%B8%82-_c/'\n",
    "yungching_crawler(url, header_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
